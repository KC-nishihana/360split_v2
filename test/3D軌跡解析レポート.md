# 3D軌跡解析レポート

## 実行日
2026年2月13日

## 概要

加速度センサー（IMU）データから3次元移動軌跡を計算・可視化しました。

---

## 📊 解析結果サマリー

| 項目 | 値 |
|------|-----|
| **サンプル数** | 2,310サンプル |
| **計測時間** | 77.04秒 |
| **サンプリングレート** | 30.0 Hz |
| **総移動距離** | **142.27メートル** |
| **直線距離** | **0.038メートル** |
| **最終位置** | (-0.022, -0.029, 0.010) m |

### 重要な観察

✅ **カメラはほぼ元の位置に戻っています**
- 総移動距離142メートルに対し、開始点からの直線距離はわずか3.8cm
- これは、撮影中にカメラが周回運動や往復運動をしていたことを示唆

---

## 🔍 データ特性

### 重力成分の推定
```
推定重力ベクトル（単位: g）:
  X: -0.324 g
  Y: -0.258 g
  Z: -0.711 g

→ カメラの姿勢: Z軸が主に下向き（重力方向）
```

### 動的加速度（重力除去後）
```
RMS値（単位: g）:
  X軸: 0.182 g
  Y軸: 0.328 g  ← 最も活発
  Z軸: 0.209 g
```

Y軸方向の動きが最も大きいことから、カメラは主に横方向（左右）に動いていたと推測されます。

---

## 📈 処理フロー

### 1. 重力成分の除去
- **手法**: 移動平均フィルタ（ウィンドウサイズ: 100サンプル）
- **目的**: 静的な重力加速度を除去し、動的な加速度のみを抽出

### 2. 速度の計算（1次積分）
```
加速度 [m/s²] → 台形則で積分 → 速度 [m/s]
```

**ドリフト除去**: 線形トレンド除去により長期的な誤差蓄積を軽減

### 3. 位置の計算（2次積分）
```
速度 [m/s] → 台形則で積分 → 位置 [m]
```

---

## 📁 出力ファイル

### 1. trajectory_3d.png
4つのビューで3D軌跡を可視化：
- **3D表示**: 時間によるグラデーション（緑→紫）
- **XY平面**: 水平面での動き
- **XZ平面**: 前後・上下の動き
- **YZ平面**: 左右・上下の動き

### 2. trajectory_timeseries.png
時系列データの可視化：
- **動的加速度**: 重力除去後の加速度
- **速度**: ドリフト除去後の速度
- **位置**: 累積された位置

### 3. trajectory_3d.csv
全データを含むCSVファイル（2,310行）：
```
列:
- TimeStamp0: 時刻 [秒]
- AccelX/Y/Z_g: 生加速度 [g]
- GravityX/Y/Z_g: 推定重力成分 [g]
- AccelDynamicX/Y/Z_ms2: 動的加速度 [m/s²]
- VelocityX/Y/Z_ms: 速度 [m/s]
- PositionX/Y/Z_m: 位置 [m]
```

---

## ⚠️ 精度に関する注意事項

### 1. IMU積分の限界
**問題**: 加速度を積分して位置を求める手法は誤差が累積しやすい

**影響**:
- ノイズや小さなバイアスも時間とともに大きな位置誤差に
- 本解析では約77秒で142メートルの移動距離を算出しているが、実際の移動距離はこれより小さい可能性が高い

### 2. ジャイロデータの欠如
**現状**: このOSVファイルにはジャイロセンサー（角速度）データが含まれていない

**影響**:
- カメラの姿勢変化を追跡できない
- 加速度の座標系補正ができない
- センサー座標系とワールド座標系の変換が不正確

### 3. 簡易的な重力除去
**手法**: 移動平均フィルタによる推定

**限界**:
- カメラの姿勢が大きく変化する場合、重力成分の除去が不完全
- より高精度な手法（カルマンフィルタなど）が必要

---

## 🔄 改善案

### 短期的改善
1. **ジャイロデータの活用**
   - exiftoolで角速度データが抽出できるか再確認
   - 姿勢推定により加速度の座標変換を実施

2. **カルマンフィルタの導入**
   - 加速度とジャイロを融合してより正確な軌跡推定
   - scipyライブラリのインストール後に高度なフィルタリング実装

3. **既知の制約条件の活用**
   - 地面との接触（Z方向の制約）
   - 速度の物理的な制限

### 長期的改善
1. **外部センサーとの融合**
   - GPS（利用可能な場合）
   - ビジュアルオドメトリ（映像フレームからの位置推定）
   - マーカー追跡

2. **機械学習による補正**
   - 既知の軌跡データを使った誤差補正モデルの学習

---

## 💡 考察

### カメラの動き
- 総移動距離142メートル、直線距離3.8cmという結果から、以下のような撮影状況が推測されます：
  1. **手持ち撮影での微振動**: カメラを持って立っている/座っている状態での細かい動き
  2. **定点での首振り**: 同じ場所で周囲を見回す動き
  3. **小さな円周上の移動**: 狭い範囲での周回移動

### データの妥当性
- RMS加速度が0.18-0.33 gという値は、手持ちカメラの典型的な値
- 最終位置が開始点に近いことは、積分誤差がそれほど大きくないことを示唆
- 速度の範囲（±4 m/s程度）は手持ち撮影として妥当

---

## 📝 使用方法

### プログラムの実行
```bash
cd /path/to/test
python3 plot_trajectory_3d_simple.py
```

### 出力ファイルの確認
```bash
# 画像を開く
open trajectory_3d.png
open trajectory_timeseries.png

# CSVデータを確認
head trajectory_3d.csv
```

### カスタマイズ
プログラム内の設定変更：
```python
GRAVITY_WINDOW = 100  # 重力推定の移動平均ウィンドウサイズ
```

---

## 🎯 まとめ

✅ **成功した点**:
- 加速度データから3D軌跡を正常に計算・可視化
- 4方向からの軌跡表示により直感的な理解が可能
- 時系列データの出力により詳細な分析が可能

⚠️ **制限事項**:
- ジャイロデータの欠如により姿勢補正が不可能
- 積分誤差により絶対位置の精度は限定的
- 簡易的な重力除去手法

💡 **推奨事項**:
- 相対的な動きの可視化としては有用
- 絶対位置の推定には外部センサーとの融合が必要
- ジャイロデータが取得できれば大幅な精度向上が期待できる

---

## 参考情報

### 生成プログラム
- `plot_trajectory_3d_simple.py`: 簡易版（scipy不要）
- `plot_trajectory_3d.py`: 高度版（scipy使用、未実行）

### 入力データ
- `imu_timeseries.csv`: 2,310サンプルのIMUデータ
- `frame_pts.csv`: フレームタイムスタンプ

### 技術スタック
- Python 3
- pandas: データ処理
- numpy: 数値計算
- matplotlib: 可視化
